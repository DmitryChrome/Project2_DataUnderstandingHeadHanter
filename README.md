# <center> Анализ резюме из HeadHunter </center>
## Оглавление
1. [Описание проекта](#Описание-проекта)
2. [Описание данных](#Описание-данных)
3. [Зависимости](#Зависимости)
4. [Установка проекта](#Установка-проекта)
5. [Использование проекта](#Использование-проекта)
6. [Авторы](#Авторы)
7. [Выводы](#Выводы)

## Описание проекта
Представьте, что вы устроились на работу в кадровое агентство, которое подбирает вакансии для IT-специалистов. Ваш первый проект — создание модели машинного обучения, которая будет рекомендовать вакансии клиентам агентства, претендующим на позицию Data Scientist. Сначала вам необходимо понять, что из себя представляют данные и насколько они соответствуют целям проекта. В литературе эта часть работы над ML-проектом называется Data Understanding, или анализ данных.  

В реальной деятельности дата-сайентисту требуется не только писать запрос к данным, но и затем обрабатывать его результаты с помощью Python. Для решения таких задач требуется некоторое средство, которое будет связывать Python и PostgreSQL так, чтобы мы могли с помощью Python отправлять запросы в Postgres и принимать оттуда результаты. Таким средством является пакет psycopg2. Установить данный пакет на любой платформе можно с помощью pip.

!pip install psycopg2

Для подключения нам потребуются следующие данные:

* dbname — название базы, к которой нужно подключиться;
* user — имя пользователя в СУБД;
* password — пароль;
* host — адрес, по которому нужно подключиться;
* port — порт, к которому нужно подключиться.

### Основные этапы работы с данными:
1. Знакомство с данными
2. Предварительный анализ данных
3. Детальный анализ вакансий
4. Анализ работодателей
5. Предметный анализ

**Цель обработки данных** — Понять структуру данных. Разобраться в их содержании. Сделать предварительные выводы.

**Данный проект** посвящен работе с SQL-запросами посредством использования Python на примере датасета вакансий с сайта по поиску работников и работадателей HeadHunter.

**О структуре проекта:**
* [Project2_DataUnderstandingHeadHanter.ipynb](./Project2_DataUnderstandingHeadHanter.ipynb) - jupyter-ноутбук, содержащий основной код проекта, в котором происходят этапы Data Understanding.

## Описание данных
В нашем распоряжении база вакансий работодателей. Схема из пяти таблиц имеющие между собой связь через уникальные идентификационные ключи.  

**VACANCIES** - Таблица хранит в себе данные по вакансиям и ID регионов и работодателей. Состоит из 10 столбцов.  

**EMPLOYERS** - таблица-справочник со списком работодателей.  

**AREAS** - таблица-справочник, которая хранит код города и его название.  

**INDUSTRIES** - таблица-справочник вариантов сфер деятельности работодателей.  

**EMPLOYERS_INDUSTRIES** - дополнительная таблица, которая существует для организации связи между работодателями и сферами их деятельности. Эта таблица нужна нам, поскольку у одного работодателя может быть несколько сфер деятельности (или работодатели могут вовсе не указать их). Для удобства анализа необходимо хранить запись по каждой сфере каждого работодателя в отдельной строке таблицы.

## Используемые зависимости
* Python (3.9):
    * [pandas (1.3.4)](https://pandas.pydata.org)
    * [psycopg2](https://www.psycopg.org/docs/)

## Установка проекта

```
git clone https://github.com/DmitryChrome/Project2_DataUnderstandingHeadHanter
```

## Использование
Вся информация о работе представлена в jupyter-ноутбуке Project2_DataUnderstandingHeadHanter.ipynb.

## Авторы

* [Dmitry Chuprinko](https://t.me/Dmitry_Chuprinko)

## Выводы

В результате проделанной работы мне удалось выполнить поставленные цели и задачи, а именно вывести все необходимые SQL-запросы посредством Python для анализа вакансий профессии Data-Science. Понять структуру данных. Выявить закономерности, сделать выводы, подкряпляя их визуализацией данных.